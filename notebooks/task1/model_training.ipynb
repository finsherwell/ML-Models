{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a37a5f",
   "metadata": {},
   "source": [
    "# Spam Detection - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca2bb5",
   "metadata": {},
   "source": [
    "- Add the project's root directory (two levels up) to the Python path so the modules can be imported, even if they arent in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddb553",
   "metadata": {},
   "source": [
    "- Import the required libraries and modules, as well as our utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b425e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.utils import load_config, get_project_root, get_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f01c0c",
   "metadata": {},
   "source": [
    "- Load the config using the utility function. Get paths to relevant folders/files needed to save and retrieve files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6474dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "train_path = config['data']['task1']['processed']['train']\n",
    "model_path = config['data']['task1']['models']\n",
    "\n",
    "processed_train_path = os.path.join(get_project_root(), train_path.replace('/', os.sep), \"spam_detection_train_processed_features.csv\")\n",
    "selected_model_path = os.path.join(get_project_root(), model_path.replace('/', os.sep))\n",
    "\n",
    "train_df = pd.read_csv(processed_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f3701",
   "metadata": {},
   "source": [
    "- Specify the columns we want to use for our features. These exist in the processed and featured data files, we just need to specify what we want to use to train models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'text_length', 'word_count', 'special_char_count', 'exclamation_density',\n",
    "    'uppercase_ratio', 'avg_sentence_length', 'punctuation_density',\n",
    "    'vocabulary_richness', 'marketing_keyword_count'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b032ef",
   "metadata": {},
   "source": [
    "- Split data into testing and validation sets. This will also allow us to assess accuracy based on accuracy, precision, recall and f1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[feature_cols]\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7a075",
   "metadata": {},
   "source": [
    "- Specify models in a dictionary - this is for clear organisation but also so we can easily iterate through it and test them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5),\n",
    "    'Bernoulli Naive Bayes': BernoulliNB(),\n",
    "    'SVC': SVC(kernel='sigmoid'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0479e87",
   "metadata": {},
   "source": [
    "- A list to store results, and variables to help us choose the best model based primarily on f1 score. Whilst it may be chosen using only f1 score, I will make sure that the choice is sensible from a bar chart diagram which compares all results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6571f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_model = None\n",
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2419202",
   "metadata": {},
   "source": [
    "- Iterate through the dictionary, make predictions, evaluate this based on the validation set, and append this to our results list along with the name of the model (as a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b79022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    results.append({'Model': name, 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1})\n",
    "    \n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    conf_matrix = get_confusion_matrix(y_val, y_pred)\n",
    "    print(f\"\\nConfusion Matrix for {name}:\\n{conf_matrix}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafd538",
   "metadata": {},
   "source": [
    "- Make a dataframe for easy plotting. The dataframe is easy to use as our results list is constructed in a sensible way. Plot a bar chart with all metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index('Model').plot(kind='bar', figsize=(12,6), title='Model Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e22e88",
   "metadata": {},
   "source": [
    "- Print out which model is best - we will choose this one. It is already trained, so ready to save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37858333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08576819",
   "metadata": {},
   "source": [
    "- Save the best model to the chosen file location. This will allow us to access it when it comes to testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12582e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"best_model.pkl\"\n",
    "\n",
    "os.makedirs(selected_model_path, exist_ok=True)\n",
    "    \n",
    "full_path = os.path.join(selected_model_path, filename)\n",
    "\n",
    "joblib.dump(best_model, full_path)\n",
    "print(f\"Model Saved: {full_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
