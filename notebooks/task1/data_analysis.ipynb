{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666a19ab",
   "metadata": {},
   "source": [
    "# Spam Detection - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15def1b",
   "metadata": {},
   "source": [
    "- Add the project's root directory (two levels up) to the Python path so the modules can be imported, even if they arent in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16053184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e22f4",
   "metadata": {},
   "source": [
    "- Import the required libraries and modules, as well as our utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "from src.utils import load_config, get_project_root, print_text\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a87a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca18918",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "- Load raw training and test data from location in configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "train_path = os.path.join(get_project_root(), config['data']['task1']['raw']['train'])\n",
    "test_path = os.path.join(get_project_root(), config['data']['task1']['raw']['test'])\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a403d",
   "metadata": {},
   "source": [
    "- Display basic information about our test and training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data Shape:\", train_df.shape)\n",
    "print(\"Test Data Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2e2b5",
   "metadata": {},
   "source": [
    "- Choose a spam and not spam message from the data, use the given function to see if it is spam or not, then print it. We can use this to get a rough idea of what a spam message might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spam_sample = train_df[train_df['label'] == 0].iloc[0]\n",
    "print(\"NON-SPAM SAMPLE:\")\n",
    "print_text(non_spam_sample['text'], non_spam_sample[-1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "spam_sample = train_df[train_df['label'] == 1].iloc[0]\n",
    "print(\"SPAM SAMPLE:\")\n",
    "print_text(spam_sample['text'], spam_sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023924f",
   "metadata": {},
   "source": [
    "## 2. Analysing Data\n",
    "- Pie chart of spam vs. non-spam distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ee7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(series, mapping):\n",
    "    return series.map(mapping).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"NotSpam\", 1: \"Spam\"}\n",
    "plot_labels = [\"NotSpam\", \"Spam\"]\n",
    "\n",
    "train_labels = map_labels(train_df.iloc[:, -1], mapping)\n",
    "train_counts = [(train_labels == \"NotSpam\").sum(), (train_labels == \"Spam\").sum()]\n",
    "\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "axes.pie(\n",
    "    train_counts,\n",
    "    labels=plot_labels,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['paleturquoise', 'orchid']\n",
    ")\n",
    "\n",
    "axes.set_title('Training Data Insight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b0693",
   "metadata": {},
   "source": [
    "- Print key information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Set - NotSpam: {train_counts[0]}, Spam: {train_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1673d3b",
   "metadata": {},
   "source": [
    "## 3. Text Length Analysis\n",
    "- Calculate average text length of a spam message vs a non-spam message.\n",
    "- Plot distribution on histogram of average text lengths for spam vs. non-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = train_df.iloc[:, 0].apply(len)\n",
    "spam_lengths = text_lengths[train_labels == \"Spam\"]\n",
    "nonspam_lengths = text_lengths[train_labels == \"NotSpam\"]\n",
    "\n",
    "spam_avg_len = spam_lengths.mean()\n",
    "nonspam_avg_len = nonspam_lengths.mean()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(nonspam_lengths, bins=30, alpha=0.6, label='NotSpam', color='paleturquoise')\n",
    "plt.hist(spam_lengths, bins=30, alpha=0.6, label='Spam', color='orchid')\n",
    "plt.title('Text Length Distribution')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf8c4d",
   "metadata": {},
   "source": [
    "- Key insights into the data, containing average text length for both spam and not spam, what the length of the largest spam message is, and how many spam messages have a length of over 500 characters. These all give us key insights into the composition of a spam message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Text Length for Spam: {spam_avg_len:.2f} characters\")\n",
    "print(f\"Average Text Length for Not Spam: {nonspam_avg_len:.2f} characters\")\n",
    "print(f\"Max Spam Length: {spam_lengths.max()}\")\n",
    "print(f\"Number of Spam Messages over 500 characters: {(spam_lengths > 500).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baceb439",
   "metadata": {},
   "source": [
    "## 4. Linguistic Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_avg_sentence(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if not sentences:\n",
    "        return 0\n",
    "    return np.mean([len(word_tokenize(sent)) for sent in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_lens = texts.apply(length_avg_sentence)\n",
    "\n",
    "labels = pd.Series(map_labels(train_df.iloc[:, -1], mapping))\n",
    "\n",
    "spam_avg_sent_len = avg_sent_lens[labels == \"Spam\"].mean()\n",
    "nonspam_avg_sent_len = avg_sent_lens[labels == \"NotSpam\"].mean()\n",
    "\n",
    "print(f\"Average Spam Sentence Length: {spam_avg_sent_len:.2f} words\")\n",
    "print(f\"Average Not Spam Sentence Length: {nonspam_avg_sent_len:.2f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09037d06",
   "metadata": {},
   "source": [
    "- Word count distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = texts.apply(lambda x: len(word_tokenize(x)))\n",
    "spam_word_counts = word_counts[labels == \"Spam\"]\n",
    "nonspam_word_counts = word_counts[labels == \"NotSpam\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(nonspam_word_counts, bins=30, alpha=0.6, label='NotSpam', color='paleturquoise')\n",
    "plt.hist(spam_word_counts, bins=30, alpha=0.6, label='Spam', color='orchid')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb349f",
   "metadata": {},
   "source": [
    "- Usage of special characters - how often are they being used in spam and not spam messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = ['!', '?', '$', '%', '&', '@', '*']\n",
    "\n",
    "def count_special_chars(text):\n",
    "    return sum(text.count(c) for c in special_chars)\n",
    "\n",
    "special_char_counts = texts.apply(lambda x: count_special_chars(x))\n",
    "\n",
    "spam_special_char_avg = special_char_counts[labels == \"Spam\"].mean()\n",
    "nonspam_special_char_avg = special_char_counts[labels == \"NotSpam\"].mean()\n",
    "\n",
    "print(f\"Average Special Characters per Spam Message: {spam_special_char_avg:.2f}\")\n",
    "print(f\"Average Special Characters per Not Spam Message: {nonspam_special_char_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769fb7",
   "metadata": {},
   "source": [
    "- Exclamation mark frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c03f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(text):\n",
    "    punctuation = '.,!?;:'\n",
    "    return sum(1 for char in text if char in punctuation)\n",
    "\n",
    "punctuation_counts = texts.apply(count_punctuation)\n",
    "\n",
    "spam_punctuation_avg = punctuation_counts[labels == \"Spam\"].mean()\n",
    "nonspam_punctuation_avg = punctuation_counts[labels == \"NotSpam\"].mean()\n",
    "\n",
    "print(f\"Average Punctuation Mark Usage per Spam Message: {spam_punctuation_avg:.2f}\")\n",
    "print(f\"Average Punctuation Mark Usage per Not Spam Message: {nonspam_punctuation_avg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e5e6e",
   "metadata": {},
   "source": [
    "- Exclamation mark density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclamation_density(text):\n",
    "    exclam = '!'\n",
    "    word_count = len(word_tokenize(text))\n",
    "    excl_count = text.count(exclam)\n",
    "    return excl_count / word_count if word_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclamation_density_counts = texts.apply(exclamation_density)\n",
    "\n",
    "spam_excl_density_avg = exclamation_density_counts[labels == \"Spam\"].mean()\n",
    "nonspam_excl_density_avg = exclamation_density_counts[labels == \"NotSpam\"].mean()\n",
    "\n",
    "print(f\"Average Exclamation Mark Density for Spam: {spam_excl_density_avg:.4f}\")\n",
    "print(f\"Average Exclamation Mark Density for Not Spam: {nonspam_excl_density_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f147648",
   "metadata": {},
   "source": [
    "## 5. Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fd332",
   "metadata": {},
   "source": [
    "- Function to find most frequent words in the passed text collection, making sure to ignore any stopwords. This gives us a good idea as to what spam and not spam messages might be composed of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_words(text_collection):\n",
    "    cv = CountVectorizer(stop_words='english', max_features=20)\n",
    "    word_counts = cv.fit_transform(text_collection)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        word_counts.toarray(),\n",
    "        columns=cv.get_feature_names_out()\n",
    "    )\n",
    "\n",
    "    word_totals = df.sum().sort_values(ascending=False)\n",
    "    return word_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18034e93",
   "metadata": {},
   "source": [
    "- Make a word cloud given a collection of text and a title to label the word cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_cloud(text_collection, title):\n",
    "    max_words = 15\n",
    "    text = \" \".join(text_collection)\n",
    "    \n",
    "    cloud = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white',\n",
    "        stopwords=None,\n",
    "        max_words=max_words\n",
    "    ).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad2a70",
   "metadata": {},
   "source": [
    "- Get all the spam and not spam texts, find the most frequent words, and print these. Also use them to make a word cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_texts = texts[labels == \"Spam\"]\n",
    "nonspam_texts = texts[labels == \"NotSpam\"]\n",
    "\n",
    "spam_word_counts = find_frequent_words(spam_texts)\n",
    "nonspam_word_counts = find_frequent_words(nonspam_texts)\n",
    "\n",
    "print(\"Most Common Words in Spam:\")\n",
    "print(spam_word_counts)\n",
    "print(\"\\n\")\n",
    "print(\"Most Common Words in Non-Spam:\")\n",
    "print(nonspam_word_counts)\n",
    "\n",
    "make_word_cloud(spam_texts, 'Word Cloud for Spam')\n",
    "make_word_cloud(nonspam_texts, 'Word Cloud for Non-Spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76808051",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8118e6f",
   "metadata": {},
   "source": [
    "- Use a dataframe to analyse whether there is any correlation between certain features - which may help when it comes to feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame({\n",
    "    'text_length': text_lengths,\n",
    "    'avg_sentence_length': avg_sent_lens,\n",
    "    'special_chars': special_char_counts,\n",
    "    'punctuation_count': punctuation_counts,\n",
    "    'exclamation_density': exclamation_density_counts,\n",
    "})\n",
    "\n",
    "correlations = features_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlations, annot=True, cmap='coolwarm', fmt=\".2f\", \n",
    "            vmin=-1, vmax=1)\n",
    "plt.title(\"Spam Detection Correlation Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
