{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6187958d",
   "metadata": {},
   "source": [
    "# Face Alignment - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12966833",
   "metadata": {},
   "source": [
    "- Add the project's root directory (two levels up) to the Python path so the modules can be imported, even if they arent in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a267279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217dcc6",
   "metadata": {},
   "source": [
    "- Import the required libraries and modules, as well as our utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c999d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import load_config, get_project_root, confirm_checksum, save_as_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84a730",
   "metadata": {},
   "source": [
    "- Load the config using the utility function. Get paths to relevant folders/files needed to save and retrieve files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c93c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "raw_test_data_checksum = config['data']['task2']['raw']['test_checksum']\n",
    "raw_train_data_checksum = config['data']['task2']['raw']['train_checksum']\n",
    "\n",
    "train_data_path = os.path.join(get_project_root(), config['data']['task2']['raw']['train'])\n",
    "test_data_path = os.path.join(get_project_root(), config['data']['task2']['raw']['test'])\n",
    "\n",
    "processed_train_data_path = config['data']['task2']['processed']['train']\n",
    "processed_test_data_path = config['data']['task2']['processed']['test']\n",
    "\n",
    "raw_test_data = os.path.join(get_project_root(), test_data_path.replace('/', os.sep))\n",
    "raw_train_data = os.path.join(get_project_root(), train_data_path.replace('/', os.sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b6c04",
   "metadata": {},
   "source": [
    "- Use the provided function to check whether the contents of the files loaded are valid or not, by checking them against a provided checksum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e50107",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confirm_checksum(raw_test_data, raw_test_data_checksum) and confirm_checksum(raw_train_data, raw_train_data_checksum):\n",
    "    print(\"Training and Testing Data Loaded Correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7590ace",
   "metadata": {},
   "source": [
    "- Load the images and the landmark data. We can load the \"npz\" file by using numpy's load function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d506a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(train_data_path, allow_pickle=True)\n",
    "test_data = np.load(test_data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_data['images']\n",
    "train_points = train_data['points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dd93c",
   "metadata": {},
   "source": [
    "- Print some key information about the shape of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Images: {train_images.shape}\")\n",
    "print(f\"Train Points: {train_points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057007c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_data['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc409839",
   "metadata": {},
   "source": [
    "- Print some key information about the shape of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Images: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233b34a",
   "metadata": {},
   "source": [
    "- Plot a sample of 3 images with their landmarks. I am doing this to help visualise the training images and where abouts the landmarks are based:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    for pt in train_points[i]:\n",
    "        plt.plot(pt[0], pt[1], 'ro')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.suptitle('Sample Images with Landmarks')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2f706",
   "metadata": {},
   "source": [
    "- This function is used to pass the image through some pre-processing steps. It converts images to grayscale, resizes them if needed and normalises pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_images(images, target_size=(96, 96)):\n",
    "    processsed = []\n",
    "    for image in images:\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "        resized = cv2.resize(image, target_size)\n",
    "        normalised = resized / 255.0\n",
    "        processsed.append(normalised)\n",
    "    \n",
    "    return np.array(processsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c25ab",
   "metadata": {},
   "source": [
    "- This function will resize the landmark coordinates to match the size of the new image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_points(points, original_shape, target_shape):\n",
    "    x = target_shape[1] / original_shape[1]\n",
    "    y = target_shape[0] / original_shape[0]\n",
    "\n",
    "    scaled_points = points.copy()\n",
    "    scaled_points[:, :, 0] *= x\n",
    "    scaled_points[:, :, 1] *= y\n",
    "\n",
    "    return scaled_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515f110",
   "metadata": {},
   "source": [
    "- Preprocess the training data and test data, making sure it is consistent throughout both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a328c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_images[0].shape[:2]\n",
    "target_shape = (96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pre_process_images(train_images, target_shape)\n",
    "processed_test = pre_process_images(test_images, target_shape)\n",
    "resized_train_points = resize_points(train_points, shape, target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b864e30",
   "metadata": {},
   "source": [
    "- Visualise how the new preprocessed images look with the resized landmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07186648",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(processed_train[i], cmap='gray')\n",
    "    \n",
    "    for pt in resized_train_points[i]:\n",
    "        plt.plot(pt[0], pt[1], 'ro')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Preprocessed Images with Landmarks')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb9ad6",
   "metadata": {},
   "source": [
    "- Save the pre-processed data so it can be loaded to extract features. We are saving it as a \"npz\" file type to keep it consistent throughout the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = os.path.join(get_project_root(), processed_train_data_path.replace('/', os.sep), \"processed_face_alignment_train_images.npz\")\n",
    "processed_test_data = os.path.join(get_project_root(), processed_test_data_path.replace('/', os.sep), \"processed_face_alignment_test_images.npz\")\n",
    "\n",
    "save_as_npz(processed_train_data, images=processed_train, points=resized_train_points)\n",
    "save_as_npz(processed_test_data, images=processed_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
