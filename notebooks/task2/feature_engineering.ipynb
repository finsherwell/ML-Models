{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9d2b3e",
   "metadata": {},
   "source": [
    "# Face Alignment - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17b6be",
   "metadata": {},
   "source": [
    "- Add the project's root directory (two levels up) to the Python path so the modules can be imported, even if they arent in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58807201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca877bab",
   "metadata": {},
   "source": [
    "- Import the required libraries and modules, as well as our utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70714090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from src.utils import load_config, get_project_root, save_as_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a421c",
   "metadata": {},
   "source": [
    "- Load the config using the utility function. Get paths to relevant folders/files needed to save and retrieve files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "processed_train_data_path = config['data']['task2']['processed']['train']\n",
    "processed_test_data_path = config['data']['task2']['processed']['test']\n",
    "\n",
    "processed_train_data = os.path.join(get_project_root(), processed_train_data_path.replace('/', os.sep), \"processed_face_alignment_train_images.npz\")\n",
    "processed_test_data = os.path.join(get_project_root(), processed_test_data_path.replace('/', os.sep), \"processed_face_alignment_test_images.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746dedc",
   "metadata": {},
   "source": [
    "- Load the images and the landmark data. We can load the \"npz\" file by using numpy's load function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(processed_train_data, allow_pickle=True)\n",
    "test_data = np.load(processed_test_data, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553dc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_data['images']\n",
    "train_points = train_data['points']\n",
    "test_images = test_data['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fcd39",
   "metadata": {},
   "source": [
    "- Extract SIFT features from an image. This will give us some key points in the image, which will be very useful when training out model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_features(image, step=4):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = [cv2.KeyPoint(x, y, step) for y in range(step, image.shape[0], step)\n",
    "                 for x in range(step, image.shape[1], step)]\n",
    "    _, descriptors = sift.compute(np.uint8(image * 255), keypoints)\n",
    "    return descriptors.flatten() if descriptors is not None else np.zeros((1, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb0cb0",
   "metadata": {},
   "source": [
    "- We will use a Canny edge detector to extract any edge-based features. This will be useful when we train our model because landmarks are near edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_features(image):\n",
    "    edges = cv2.Canny(np.uint8(image * 255), 100, 200)\n",
    "    return (edges[::4, ::4].flatten() / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2510c9f",
   "metadata": {},
   "source": [
    "- This extracts some basic statistics about the intensity - this is the mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f34763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intensity_stats(image):\n",
    "    return np.array([np.mean(image), np.std(image)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f6d5a",
   "metadata": {},
   "source": [
    "- We will combine all these features into one vector. This just means our \"npz\" file will have one extra attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    sift_feat = extract_sift_features(image)\n",
    "    edge_feat = extract_edge_features(image)\n",
    "    intensity_feat = extract_intensity_stats(image)\n",
    "    return np.concatenate([sift_feat, edge_feat, intensity_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9775d5",
   "metadata": {},
   "source": [
    "- Extract the features from the images in the training dataset and the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [extract_features(img) for img in train_images]\n",
    "X_test = [extract_features(img) for img in test_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc50cae",
   "metadata": {},
   "source": [
    "- Convert into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feca923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e72b2",
   "metadata": {},
   "source": [
    "- Save the extracted features to a new file which can be retrieved and used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processed_train_data = os.path.join(get_project_root(), processed_train_data_path.replace('/', os.sep), \"processed_face_alignment_train_images_features.npz\")\n",
    "feature_processed_test_data = os.path.join(get_project_root(), processed_test_data_path.replace('/', os.sep), \"processed_face_alignment_test_images_features.npz\")\n",
    "\n",
    "save_as_npz(feature_processed_train_data, images = train_images, points = train_points, features = X_train)\n",
    "save_as_npz(feature_processed_test_data, images = test_images, features = X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
